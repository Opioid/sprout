* Backlog

** Miscellaneous [1/1]

*** DONE PCG Random Number Generator 
[[http://www.pcg-random.org/]]

** Integrators [0/1]

*** TODO Subsurface scattering [0/2]
- [-] Implement single scattering
  - [X] Direct light only
  - [ ] Indirect illumination
- [ ] Implement multiple scattering
  - [ ] Monte-carlo integrator
  - [ ] Next event estimation

** Materials [0/3]

*** TODO Microfacets [2/3]
**** DONE Correlated shadowing/masking function [2/2]
- [X] Reflections
- [X] Refractions

[[https://seblagarde.files.wordpress.com/2015/07/course_notes_moving_frostbite_to_pbr_v32.pdf]]
[[http://twvideo01.ubm-us.net/o1/vault/gdc2017/Presentations/Hammon_Earl_PBR_Diffuse_Lighting.pdf]]

**** DONE Look into normalized Disney BRDF (see frostbite presentation)
The results look very good. Apparently rough surfaces were much too bright before.
I'm not sure what this means for the subsurface scattering case, but I tried to modify it accordingly.

**** TODO Thin-film [0/2]
- [ ] Implement [[https://belcour.github.io/blog/research/2017/05/01/brdf-thin-film.html]]
- [ ] Evaluate difference to existing thin-film Fresnel

*** TODO Cloth material
Investigate dedicated cloth material with alternative BRDF (e.g. Ashikhmin)

*** TODO Separate samplers
Consider adding support for separate samplers per different textures in a single material.
E.g nearest neighbor filter for albedo color and bilinear for normal map.

** Renderer [0/2]

*** TODO Lock-free tile enumeration [1/2]
- [X] Pre-determined "Tiled scanline" with initial offset (slower)
- [ ] Atomics for access to next tile

It seems that the mutex communication is not the bottleneck in this scenario. 
Something with atomics might be interesting, but will probably not noticeably affect overall performance.

*** TODO Deterministic random numbers
Currently (some) random numbers are seeded per worker.
This leads to indeterministic behavior as the workers render varying parts of the frame per run.
For a deterministic result the seed should always be the same per pixel/tile in any run.
Of course, this should have no impact on the converged result and only affect noise. 

** Postprocessors [0/1]

*** TODO Glare filter [1/3]
Implement in Fourier domain to increase performance
- [X] Use normal DFT to transform to Fourier domain and back
- [ ] Investigate decreased quality, lattice like artifacts
- [ ] Use FFT to improve performance

** Shapes [0/2]

*** TODO Adding/improving analytical shapes [1/2]
- [X] Canopy/Half-sphere
  - [X] Intersection
  - [X] UV sampling (works all of a sudden?)
- [ ] Cylinder

*** TODO Consider visibility settings per part

** Resources [0/1]

*** TODO Faster file loading [1/3]
- [X] Consider concurrent loading during lengthy processing steps (e.g. building BVH)
- [-] Consider embedding json and binary data in single file
  - [X] Proof of concept
  - [ ] Support different vertex layouts
- [ ] Investigate performance of std::stream vs. fread() etc.

There is a very simple mechanism for asynchronous BVH construction now. 
It seems to work reasonably well in cases where BVH construction is followed by lengthy reads from disk.
A typical example is when texture data is being loaded during BVH construction.

Proof of concept for binary files showed good improvements in loading time. 
File size on disk generally seems to be higher, though (somewhat surprisingly for me).

** Build system [0/2]

*** TODO Investigate more Travis CI usage

*** TODO Consider cmake-based build system

** Scene [1/2]

*** TODO Faster scene update [0/2]
Investigate opportunities to parallelize some parts of scene update

- [-] Calculation of distribution LUTs for light sources
  - [X] Image
  - [ ] Mesh
- [ ] Updating of entity transformations

The results are disappointing so far (e.g. less than 2x speedup for 12 threads).

*** DONE Streamline zero lights case
For example by automatically adding a null-light to scenes that otherwise don't have a light. 
This would remove some checks spread out over the codebase. 
